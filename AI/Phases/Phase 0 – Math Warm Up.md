---
tags: [ai, math, foundations, warmup]
phase: 0
duration: 2-3 weeks
---

# ðŸ”§ Phase 0 â€“ Math Warm Up (Calculus + Discrete Math Refresh)

## ðŸŽ¯ Objective

Refresh the exact math needed for machine learning without going full academic.

This phase prepares you for:

- [[Softmax]]
- [[Cross Entropy Loss]]
- [[Gradient Descent]]
- [[Attention Equation]]

You do NOT need deep proofs â€” only working intuition.

---

# ðŸ§­ Structure

Daily (~60â€“90 min):

- 30 min structured course/video
- 30 min reading / notes
- optional 15 min exercises

---

# Week 0.1 â€” Algebra & Functions Refresher

## Concepts

- [[Functions]]
- [[Exponential Functions]]
- [[Logarithms]]
- [[Summations]]
- [[Sigma Notation]]

Why this matters:

Softmax and cross-entropy are mostly exponentials and logs.

Checkpoint:

> I understand how log(exp(x)) behaves and why logs compress scale.

---

# Week 0.2 â€” Calculus Essentials for ML

## Focus ONLY on:

- [[Derivatives]]
- [[Partial Derivatives]]
- [[Chain Rule]]
- [[Gradients]]

Ignore:

- integration tricks
- formal epsilon proofs

Mental Model:

Gradient = direction of steepest increase.

Checkpoint:

> I can visualize a loss surface and a slope.

---

# Week 0.3 â€” Vectors & Discrete Math Intuition

## Concepts

- [[Vectors]]
- [[Dot Product]]
- [[Vector Spaces]]
- [[Combinatorics Basics]]
- [[Probability Notation]]
Untitled
Why:

Transformers are mostly vector math disguised as matrices.

Checkpoint:

> I understand similarity as a dot product.

---

# ðŸ“š Recommended Resources (Lightweight but Strong)

## Primary Videos

- 3Blue1Brown â€” Essence of Linear Algebra
- 3Blue1Brown â€” Essence of Calculus

Watch slowly, take visual notes.

---

## Optional Structured Course

Khan Academy:

- Multivariable Calculus (selected sections)
- Probability Basics

---

## Reading Support

Use:

- [[Mathematics for Machine Learning]] (skim sections only)

Do NOT try to master every proof.

---

# ðŸ§  Key Mental Models to Capture

Create permanent notes for:

- [[Derivative Intuition]]
- [[Log vs Exponential]]
- [[Gradient Intuition]]
- [[Vector Similarity]]

These will be referenced constantly later.

---

# âš ï¸ Common Trap

Do NOT turn this into a 2-month math marathon.

Goal:

> Become comfortable seeing math â€” not mastering mathematics.

Once derivatives and logs stop feeling scary, move to [[Phase 1 - Math Foundations]].
